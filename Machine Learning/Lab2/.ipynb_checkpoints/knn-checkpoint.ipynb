{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIpznYI8eJmV"
   },
   "source": [
    "# Lab 2\n",
    "### Machine Learning 1\n",
    "\n",
    "This assignment is to be done with a partner. Please only submit ONE .ipynb (not .py) file per pair!\n",
    "\n",
    "**Enter your names and student numbers here:**\n",
    "\n",
    "- Niek Horstman (9593977)\n",
    "- Tobias Middelhoff (9676945)\n",
    "- JoÃ«l van de Water (9145532)\n",
    "\n",
    "**Total points: 8**\n",
    "\n",
    "In Lab 2 you will get to know an easy but powerful Machine Learning method: the k-Nearest Neighbours algorithm (kNN). We will use the method on a classification problem, a case of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAd1sXE3eJmX"
   },
   "source": [
    "## The data\n",
    "\n",
    "We will look at data originally from an Australian bank. Based on some information about a customer, the bank has to decide whether this customer's application for a credit card will be approved or not.\n",
    "(The original data file can be found here: https://archive.ics.uci.edu/ml/datasets/Statlog+(Australian+Credit+Approval), but for convenience we have already provided two .txt files with this assignment.)\n",
    "The data of each customer is described by 14 variables. Four of these are categorical variables: they assign a label to each customer. These labels are represented by integers. (To protect the privacy of the customers, there is no information about the meaning of the variables and thus not about the meaning of the different labels.) Four other variables are binary (0 or 1). The other six variables are real numbers. Together they constitute the input: the vector *x*.\n",
    "Each customer also has their output variable *y*, which is 0 or 1. This indicates whether the customer's application (according to human experts) should be approved (*y=1*) or not (*y=0*).\n",
    "\n",
    "We want to write an algorithm for this task that learns from the expert decisions it has seen and is able to make its own decisions for new customers.\n",
    "\n",
    "## The algorithm\n",
    "\n",
    "The Nearest Neighbour algorithm is based on a simple idea: we are going to base the decision for a new customer (approve credit card application or not) on the decision for a customer in the training data (the historical data). We base it on the customer who is most similar to the new customer.\n",
    "To use this in an algorithm, we first need a measure which can be used to determine the similarity between two customers. We will use the *Euclidean* distance for this purpose.\n",
    "\n",
    "If we consider a customer to be a point in a 14-dimensional space (one dimension for each variable), we can calculate the Euclidean distance between two customers/points *A* and *B* with:\n",
    "\n",
    "$$\\sqrt{(A_1-B_1)^2+(A_2-B_2)^2+...+(A_{14}-B_{14})^2}$$\n",
    "\n",
    "with $A_1$ the first input variable of $A$, $A_2$ the second, etc.\n",
    "\n",
    "The algorithm has the following simple steps, with step 3 being an evaluation of how well the algorithm is doing:\n",
    "\n",
    "1. Read the training data from the file;\n",
    "2. For every customer $c_{test}$ in the test file: determine which customer $c_{train}$ in the training data has the smallest Euclidean distance to the test-customer $c_{test}$, and assign the decision corresponding to $c_{train}$ to $c_{test}$;\n",
    "3. Count the number of test-customers for which the decision made by the algorithm is the same as the decision made by human experts;\n",
    "\n",
    "Step 1 is already implemented below in the two classes **Data** and **Person**.\n",
    "Person is a class containing all customer information: the input vector *x* and the output *y*. The inputs are divided in three different arrays: *xCategorical*, *xBinary* and *xReal*; the output is *y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bpZ4FmHeJmY"
   },
   "outputs": [],
   "source": [
    "class Person:\n",
    "  def __init__(self, line_text):\n",
    "    # integers\n",
    "    self.xCategorical = [None]*4\n",
    "    # integers\n",
    "    self.xBinary = [None]*4\n",
    "    # floats\n",
    "    self.xReal = [None]*6\n",
    "\n",
    "    # label (0 or 1)\n",
    "    self.y = None\n",
    "    # Initialize the features\n",
    "    self.fromString(line_text)\n",
    "\n",
    "  def fromString(self, line_text):\n",
    "    self.xBinary[0] = int(line_text[0])\n",
    "    self.xReal[0] = float(line_text[1])\n",
    "    self.xReal[1] = float(line_text[2])\n",
    "    self.xCategorical[0] = int(line_text[3])\n",
    "    self.xCategorical[1] = int(line_text[4])\n",
    "    self.xCategorical[2] = int(line_text[5])\n",
    "    self.xReal[2] = float(line_text[6])\n",
    "    self.xBinary[1] = int(line_text[7])\n",
    "    self.xBinary[2] = int(line_text[8])\n",
    "    self.xReal[3] = float(line_text[9])\n",
    "    self.xBinary[3] = int(line_text[10])\n",
    "    self.xCategorical[3] = int(line_text[11])\n",
    "    self.xReal[4] = float(line_text[12])\n",
    "    self.xReal[5] = float(line_text[13])\n",
    "\n",
    "    self.y = int(line_text[14])\n",
    "\n",
    "  def __str__(self):\n",
    "    person_info = \"x = (\" + \\\n",
    "\t    str(self.xBinary[0]) + \"; \" + \\\n",
    "\t    str(self.xReal[0]) + \"; \" + \\\n",
    "\t    str(self.xReal[1]) + \"; \" + \\\n",
    "\t    str(self.xCategorical[0]) + \"; \" + \\\n",
    "\t    str(self.xCategorical[1]) + \"; \" + \\\n",
    "\t    str(self.xCategorical[2]) + \"; \" + \\\n",
    "\t    str(self.xReal[2]) + \"; \" + \\\n",
    "\t    str(self.xBinary[1]) + \"; \" + \\\n",
    "\t    str(self.xBinary[2]) + \"; \" + \\\n",
    "\t    str(self.xReal[3]) + \"; \" + \\\n",
    "\t    str(self.xBinary[3]) + \"; \" + \\\n",
    "\t    str(self.xCategorical[3]) + \"; \" + \\\n",
    "\t    str(self.xReal[4]) + \"; \" + \\\n",
    "\t    str(self.xReal[5]) + \\\n",
    "\t    \"); y = \" + str(self.y)\n",
    "    return person_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMcbN1bheJma"
   },
   "source": [
    "The class Data contains a dataset in the format of *credit_train.txt* or *credit_test.txt* (training data and test data) and uses the Person class to represent the customers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb4NWzhEeJma"
   },
   "outputs": [],
   "source": [
    "class Data():\n",
    "  def __init__(self, filename):\n",
    "    self.data = []\n",
    "    self.loadFile(filename)\n",
    "\n",
    "  def loadFile(self,filename):\n",
    "    with open(filename) as file:\n",
    "      lines = file.readlines()\n",
    "      for line in lines:\n",
    "        person = Person(line.split())\n",
    "        self.data.append(person)\n",
    "\n",
    "  def printList(self):\n",
    "    for person in self.data:\n",
    "      print(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeHOdjJdeJmb"
   },
   "source": [
    "### A note on classes\n",
    "\n",
    "You may have not had the concept of Python classes yet in Computational Linguistics, but Python classes are similar to C# classes. In this case, the classes are just reading in the data and ordering it by way of named variables tied to the class name.\n",
    "\n",
    "Suppose you have an instance of the class `Person` called `john`. If you want to know the label for `john`, you call:\n",
    "\n",
    "`john.y`\n",
    "\n",
    "If you have loaded the training data as an instance of the class `Data` called `trainData`, you would access the data by calling:\n",
    "\n",
    "`trainData.data`\n",
    "\n",
    "The same goes for methods (such as the method `printList` in `Data`). The method `__str__` in `Person` is not meant to be called by the user using that name. Rather, it is the method that gets called automatically by Python when you run:\n",
    "\n",
    "`print(john)`\n",
    "\n",
    "(assuming `john` is an instance of `Person`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz4y1VW9eJmb"
   },
   "source": [
    "If you run the code below (the first time you have to run the cells above as well), you can get an idea of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfIfy6bQeJmb"
   },
   "outputs": [],
   "source": [
    "trainData = Data(\"credit_train.txt\")\n",
    "trainData.printList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jf-y2kWeJmc"
   },
   "source": [
    "Complete the implementation of the algorithm.\n",
    "\n",
    "**1. Start with writing a function computeDistance(person1, person2)** (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUJ6DZ9deJmc"
   },
   "outputs": [],
   "source": [
    "# person1 and person2 are instances of Person, and the return value should be a float\n",
    "def computeDistance(person1, person2):\n",
    "    person1 = \n",
    "    person2\n",
    "    for d in person1.y:\n",
    "        afstand = d*\n",
    "    pass # Remove this statement after having filled in the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvW041imeJmd"
   },
   "outputs": [],
   "source": [
    "def testComputeDistance():\n",
    "    person1 = Person(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\".split())\n",
    "    person2 = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    distance = computeDistance(person1, person2)\n",
    "    expected_distance = 1213.5008265757383\n",
    "    assert abs(distance - expected_distance) / expected_distance < 1e-6\n",
    "\n",
    "testComputeDistance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1wNiSYDeJmd"
   },
   "source": [
    "**2. Load the test data as well** (0.5 points)\n",
    "\n",
    "The function must return an instance of the class Data, containing the test data, which you read from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_JBIV-BeJmd"
   },
   "outputs": [],
   "source": [
    "def loadTestData() -> Data:\n",
    "    # FILL THIS IN (see a couple of cells above)\n",
    "\n",
    "testData = loadTestData()\n",
    "testData.printList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHviRGupeJmd"
   },
   "source": [
    "**3. Write the function giveCredit** (1 point)\n",
    "\n",
    "Given a `Person`, giveCredit predicts a decision (to approve the credit card application or not), only based on the `Person` in the training data that is closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_gOn6kZeJmd"
   },
   "outputs": [],
   "source": [
    "# Library we will use as part of the tests\n",
    "import os\n",
    "\n",
    "# This is the heart of the kNN algorithm. You pass in an instance of Person and an instance of Data\n",
    "# The return value should be a bool (True or False)\n",
    "def giveCredit(person, trainData):\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q76XlNGTeJme"
   },
   "outputs": [],
   "source": [
    "def testGiveCredit():\n",
    "    # This is a simple test to check that the method above works well\n",
    "    with open('test_give_credit.txt', 'w') as f:\n",
    "        f.write(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    trainData = Data('test_give_credit.txt')\n",
    "    testPerson = Person(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\".split())\n",
    "    creditDecision = giveCredit(testPerson, trainData)\n",
    "    expectedDecision = True\n",
    "    assert creditDecision == expectedDecision\n",
    "    # Remove the accessory file we created\n",
    "    os.remove('test_give_credit.txt')\n",
    "\n",
    "testGiveCredit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD6Oh8XHeJme"
   },
   "source": [
    "**4. Write the function getErrorPercentage** (1 point)\n",
    "\n",
    "getErrorPercentage determines the percentage of the test data that is wrongly classified. (Make sure that in all cases, you use the *y* from the test data only to check whether the classification of the algorithm was wrong or correct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Csn0CieJme"
   },
   "outputs": [],
   "source": [
    "def getErrorPercentage(trainData: Data, testData: Data) -> float:\n",
    "    # FILL THIS IN\n",
    "    # Hint: you need to iterate over all test datapoints, and for each of them, call the giveCredit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Y0n7phFeJme"
   },
   "outputs": [],
   "source": [
    "def testGetErrorPercentage():\n",
    "    # A simple function to check that the function above works correctly\n",
    "    with open('test_give_credit_train.txt', 'w') as f:\n",
    "        f.write(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    trainData = Data('test_give_credit_train.txt')\n",
    "    with open('test_give_credit_test.txt', 'w') as f:\n",
    "        f.write(\"0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    testData = Data('test_give_credit_test.txt')\n",
    "    errorPercentage = getErrorPercentage(trainData, testData)\n",
    "    assert errorPercentage == 50, errorPercentage\n",
    "    # Remove the accessory files we created\n",
    "    os.remove('test_give_credit_train.txt')\n",
    "    os.remove('test_give_credit_test.txt')\n",
    "\n",
    "testGetErrorPercentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYtexQ7weJme"
   },
   "source": [
    "What percentage is wrongly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKVI8KUNeJme"
   },
   "outputs": [],
   "source": [
    "print(\"Wrongly classified:\", getErrorPercentage(trainData, testData), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9pKux4beJmf"
   },
   "source": [
    "## Normalising the data\n",
    "In our training data, some of the variables have very large values (up to thousands), and others have very small ones\n",
    "(like the binary variables). When you interpret the data as a set of points, this makes the training data very 'stretched' in some directions and compressed in other directions. This way, the variables with large values will dominate in the decision, whereas the smaller variables will hardly play a part. This is undesirable, because if a variable is represented in large numbers, it does not mean the variable is more important than other variables.\n",
    "\n",
    "This is why we are going to standardize or normalise the data: we divide all *real* variables by a number, such that the difference between the minimum and the maximum is 1. This way the real variables have the same scale as the binary variables (we leave the categorical variables for now).\n",
    "We can do this by calculating the minimum $min_i$ and maximum $max_i$ for each variable $i$, and in the formula for the Euclidean distance, for each real valued variable *i*, we replace\n",
    "\n",
    "$$ ... + (A_i - B_i)^2 + ... $$\n",
    "\n",
    "with\n",
    "\n",
    "$$  ... +\\left(\\frac{A_i - B_i}{max_i - min_i}\\right)^2 + ...$$\n",
    "\n",
    "\n",
    "**5. Write a function that determines the minimum and maximum for each real valued variable** (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8EjuzxLeJmf"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are many ways to do this, but the way I recommend is the following:\n",
    "1) iterate over all the training data, and determine the maximum and minimum value for each real-valued variable\n",
    "2) return those maximum and minimum values in a list, which can then be used by the functions below\n",
    "\"\"\"\n",
    "def getRealBounds(data: Data) -> list:\n",
    "    # This takes a dataset as input (you will use trainData),\n",
    "    # and outputs a list of bounds for the real-values variables\n",
    "    # Output: [(min, max), (min, max), ..., (min, max)] -> one 2-tuple for each real-valued variable\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMG277UreJmf"
   },
   "outputs": [],
   "source": [
    "def testGetRealBounds():\n",
    "    # Check if the method above works as expected\n",
    "    # First create some mock data\n",
    "    with open('mock_data.txt', 'w') as f:\n",
    "        f.write(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\\n\")\n",
    "        f.write(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\\n\")\n",
    "        f.write(\"0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    mockData = Data('mock_data.txt')\n",
    "    # Note that the indices of the real-valued variables are 1, 2, 6, 9, 12, 13\n",
    "    # We can read the minima and maxima off from the input text\n",
    "    expected_bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    # Now use the method above to find the bounds\n",
    "    real_bounds = getRealBounds(mockData)\n",
    "    assert expected_bounds == real_bounds\n",
    "    # Delete the accessory file we created\n",
    "    os.remove('mock_data.txt')\n",
    "\n",
    "testGetRealBounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJf00Ll5eJmf"
   },
   "source": [
    "**6. Write a new distance function _computeDistance2_** (0.5 points)\n",
    "\n",
    "computeDistance2 scales the real valued variables before the distance is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Xxl7AmReJmf"
   },
   "outputs": [],
   "source": [
    "# Hint: Start by copying your computeDistance function from above\n",
    "# Rename the function as computeDistance2, then make the necessary changes\n",
    "# Note that this function now NEEDS to know the real-variable bounds, so we need to add one more parameter\n",
    "def computeDistance2(person1, person2, realBounds):\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACA6lWDleJmg"
   },
   "outputs": [],
   "source": [
    "def testComputeDistance2():\n",
    "    # Check that the function above does as expected\n",
    "    person1 = Person(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\".split())\n",
    "    person2 = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    expected_distance = 4.50345939998121\n",
    "    computed_distance = computeDistance2(person1, person2, bounds)\n",
    "    assert abs(expected_distance - computed_distance) / expected_distance < 1e-4, (expected_distance, computed_distance)\n",
    "\n",
    "testComputeDistance2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNEtBk5xeJmg"
   },
   "source": [
    "**7. What percentage of the test data is wrongly classified using this distance function?** (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sn5ViLlUeJmg"
   },
   "outputs": [],
   "source": [
    "# Now we need to copy the function getErrorPercentage that we wrote above, but we need to use the new distance\n",
    "# This means we also need to copy and modify giveCredit\n",
    "# If we leave the signature (parameters) of giveCredit as they are, then we will compute the bounds for every test\n",
    "# datapoint. That is a waste of time. So we will pass the (known) bounds to giveCredit\n",
    "def giveCredit2(person, trainData, realBounds):\n",
    "    # FILL THIS IN\n",
    "    # Hint: this function has to call computeDistance2\n",
    "\n",
    "def getErrorPercentage2(trainData: Data, testData: Data) -> float:\n",
    "    # FILL THIS IN\n",
    "    # Hint: this function has to call getRealBounds and computeDistance2\n",
    "    # If you do not call getRealBounds first, and instead normalize every distance on the fly, your code\n",
    "    # will be too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBgD6RnNeJmg"
   },
   "outputs": [],
   "source": [
    "def testGiveCredit2():\n",
    "    # This is a simple test to check that the method above works well\n",
    "    with open('test_give_credit.txt', 'w') as f:\n",
    "        f.write(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    trainData = Data('test_give_credit.txt')\n",
    "    testPerson = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    creditDecision = giveCredit2(testPerson, trainData, bounds)\n",
    "    expectedDecision = False\n",
    "    assert creditDecision == expectedDecision\n",
    "    # Remove the accessory file we created\n",
    "    os.remove('test_give_credit.txt')\n",
    "\n",
    "def testGetErrorPercentage2():\n",
    "    # A simple function to check that the function above works correctly\n",
    "    with open('test_give_credit_train.txt', 'w') as f:\n",
    "        f.write(\"\"\"1 39.58 13.915 2 9 4 8.625 1 1 6 1 2 70 1 1\n",
    "1 23.17 0 2 13 4 0.085 1 0 0 0 2 0 1 1\n",
    "1 63.33 0.54 2 8 4 0.585 1 1 3 1 2 180 1 0\n",
    "1 23.75 0.415 1 8 4 0.04 0 1 2 0 2 128 7 0\n",
    "\"\"\")\n",
    "    trainData = Data('test_give_credit_train.txt')\n",
    "    with open('test_give_credit_test.txt', 'w') as f:\n",
    "        f.write(\"0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    testData = Data('test_give_credit_test.txt')\n",
    "    errorPercentage = getErrorPercentage2(trainData, testData)\n",
    "    assert errorPercentage == 50, errorPercentage\n",
    "    # Remove the accessory files we created\n",
    "    os.remove('test_give_credit_train.txt')\n",
    "    os.remove('test_give_credit_test.txt')\n",
    "\n",
    "testGiveCredit2()\n",
    "testGetErrorPercentage2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDFgAm3leJmg"
   },
   "outputs": [],
   "source": [
    "print(\"Wrongly classified with real value normalization:\", getErrorPercentage2(trainData, testData), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeFm3v8xeJmh"
   },
   "source": [
    "For the categorical variables, the distance function now makes a different mistake. It assumes that points with labels 1 and 2 in a certain categorical variable are very similar but a label 14 in that variable is totally different. However, these numbers are only dummy values that represent certain labels. For two customers, we can only say whether they are in the same category or not. The data does not say anything about the grades of similarity between categories.\n",
    "\n",
    "**8. Write a third distance function computeDistance3** (0.5 points)\n",
    "\n",
    "computeDistance3 acts the same on binary and real values as _computeDistance2_, but simply uses 0 or 1 for categorical variables instead of $...+(A_i-B_i)^2+...$. That is, it should use $0$ if $A_i = B_i$, and $1$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZbWQyQieJmh"
   },
   "outputs": [],
   "source": [
    "# Start by copying your computeDistance2 function from above\n",
    "# Rename the function as computeDistance3, then make the necessary changes\n",
    "def computeDistance3(person1, person2, realBounds):\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci3x-gEYeJmh"
   },
   "outputs": [],
   "source": [
    "def testComputeDistance3():\n",
    "    # Check that the function above does as expected\n",
    "    person1 = Person(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\".split())\n",
    "    person2 = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    expected_distance = 2.29807453475276\n",
    "    computed_distance = computeDistance3(person1, person2, bounds)\n",
    "    assert abs(expected_distance - computed_distance) / expected_distance < 1e-4\n",
    "\n",
    "testComputeDistance3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYA6yaCteJmh"
   },
   "source": [
    "**9. Implement giveCredit3 and getErrorPercentage3** (0.5 points)\n",
    "\n",
    "Calculate the percentage of the test data that is wrongly classified if the algorithm uses _computeDistance3_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htJ6UoxleJmh"
   },
   "outputs": [],
   "source": [
    "# Now we need to copy the function getErrorPercentage2 that we wrote above, but we need to use the new distance\n",
    "# This means we also need to copy and modify giveCredit2\n",
    "def giveCredit3(person, trainData, realBounds):\n",
    "    # FILL THIS IN\n",
    "\n",
    "def getErrorPercentage3(trainData: Data, testData: Data) -> float:\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uVZ2DEpeJmi"
   },
   "outputs": [],
   "source": [
    "def testGiveCredit3():\n",
    "    # This is a simple test to check that the method above works well\n",
    "    with open('test_give_credit.txt', 'w') as f:\n",
    "        f.write(\"1 22.08 11.46 2 4 4 1.585 0 0 0 1 2 100 1213 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    trainData = Data('test_give_credit.txt')\n",
    "    testPerson = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    creditDecision = giveCredit3(testPerson, trainData, bounds)\n",
    "    expectedDecision = False\n",
    "    assert creditDecision == expectedDecision\n",
    "    # Remove the accessory file we created\n",
    "    os.remove('test_give_credit.txt')\n",
    "\n",
    "def testGetErrorPercentage3():\n",
    "    # A simple function to check that the function above works correctly\n",
    "    with open('test_give_credit_train.txt', 'w') as f:\n",
    "        f.write(\"\"\"1 39.58 13.915 2 9 4 8.625 1 1 6 1 2 70 1 1\n",
    "1 23.17 0 2 13 4 0.085 1 0 0 0 2 0 1 1\n",
    "1 63.33 0.54 2 8 4 0.585 1 1 3 1 2 180 1 0\n",
    "1 23.75 0.415 1 8 4 0.04 0 1 2 0 2 128 7 0\n",
    "\"\"\")\n",
    "    trainData = Data('test_give_credit_train.txt')\n",
    "    with open('test_give_credit_test.txt', 'w') as f:\n",
    "        f.write(\"0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    testData = Data('test_give_credit_test.txt')\n",
    "    errorPercentage = getErrorPercentage3(trainData, testData)\n",
    "    assert errorPercentage == 0, errorPercentage\n",
    "    # Remove the accessory files we created\n",
    "    os.remove('test_give_credit_train.txt')\n",
    "    os.remove('test_give_credit_test.txt')\n",
    "\n",
    "testGiveCredit3()\n",
    "testGetErrorPercentage3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWYHLDiceJmi"
   },
   "outputs": [],
   "source": [
    "print(\"Wrongly classified with real normalization and categorical binarization:\",\n",
    "      getErrorPercentage3(trainData, testData), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i6EB9MreJmi"
   },
   "source": [
    "## From NN to kNN\n",
    "The algorithm as described above is called the 1-Nearest Neighbour-algorithm. This is a special case of the *k*-Nearest Neighbours-algorithm. In the *kNN* algorithm,  we do not look at only 1 'neighbour', but the *k* points in the training data that are closest to the point we are classifying. Our new prediction is the decision that has a majority. Usually, odd numbers are used for *k*, so we do not have to worry about the case where there is an equal division.\n",
    "At *k=1* the boundary between the two areas where the algorithm approves/rejects is very uneven. By making *k* bigger the shape of the boundary is less determined by single points in the training data. This makes the boundary more smooth, which often leads to better predictions.\n",
    "\n",
    "**10. Adapt getCredit and getErrorPercentage to k-Nearest Neighbours** (1 point)\n",
    "\n",
    "Modify the classification function in such a way that it uses the k-NN algorithm. Make *k* an argument of the function. You can assume that $k \\in \\{1,3,5\\}$. Use the last distance function *computeDistance3* from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJKb2Fa-eJmp"
   },
   "outputs": [],
   "source": [
    "# The distance did not change, so we will just modify giveCredit3 and getErrorPercentage3\n",
    "# We will rename them as giveCreditk and getErrorPercentagek, to reflect the choice of neighbours\n",
    "# We need to take in the new parameter k\n",
    "def giveCreditk(person, trainData, realBounds, k):\n",
    "    # FILL THIS IN\n",
    "\n",
    "def getErrorPercentagek(trainData: Data, testData: Data, k: int) -> float:\n",
    "    # FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80s24wj4eJmp"
   },
   "outputs": [],
   "source": [
    "def testGiveCreditk():\n",
    "    # This is a simple test to check that the method above works well\n",
    "    with open('test_give_credit.txt', 'w') as f:\n",
    "        f.write(\"\"\"1 23.08 2.5 2 8 4 1.085 1 1 11 1 2 60 2185 1\n",
    "1 27 0.75 2 8 8 4.25 1 1 3 1 2 312 151 1\n",
    "0 20.42 10.5 1 14 8 0 0 0 0 1 2 154 33 0\n",
    "1 52.33 1.375 1 8 8 9.46 1 0 0 1 2 200 101 0\n",
    "\"\"\")\n",
    "    trainData = Data('test_give_credit.txt')\n",
    "    testPerson = Person(\"0 22.67 7 2 8 4 0.165 0 0 0 0 2 160 1 0\".split())\n",
    "    bounds = [(15.83, 29.58), (0.585, 11.46), (0.165, 1.585), (0, 2), (100, 280), (1, 1213)]\n",
    "    creditDecision = giveCreditk(testPerson, trainData, bounds, 3)\n",
    "    expectedDecision = True\n",
    "    assert creditDecision == expectedDecision\n",
    "    # Remove the accessory file we created\n",
    "    os.remove('test_give_credit.txt')\n",
    "\n",
    "def testGetErrorPercentagek():\n",
    "    # A simple function to check that the function above works correctly\n",
    "    with open('test_give_credit_train.txt', 'w') as f:\n",
    "        f.write(\"\"\"1 39.58 13.915 2 9 4 8.625 1 1 6 1 2 70 1 1\n",
    "1 23.17 0 2 13 4 0.085 1 0 0 0 2 0 1 1\n",
    "1 63.33 0.54 2 8 4 0.585 1 1 3 1 2 180 1 0\n",
    "1 23.75 0.415 1 8 4 0.04 0 1 2 0 2 128 7 0\n",
    "\"\"\")\n",
    "    trainData = Data('test_give_credit_train.txt')\n",
    "    with open('test_give_credit_test.txt', 'w') as f:\n",
    "        f.write(\"0 29.58 1.75 1 4 4 1.25 0 0 0 1 2 280 1 0\\n\")\n",
    "        f.write(\"0 15.83 0.585 2 8 8 1.5 1 1 2 0 2 100 1 1\\n\")\n",
    "    testData = Data('test_give_credit_test.txt')\n",
    "    errorPercentage = getErrorPercentagek(trainData, testData, 3)\n",
    "    assert errorPercentage == 50, errorPercentage\n",
    "    # Remove the accessory files we created\n",
    "    os.remove('test_give_credit_train.txt')\n",
    "    os.remove('test_give_credit_test.txt')\n",
    "\n",
    "testGiveCreditk()\n",
    "testGetErrorPercentagek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqnmI1uzeJmp"
   },
   "source": [
    "**11. What are the test results for the different values of *k*?** (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6r1B47LueJmp"
   },
   "outputs": [],
   "source": [
    "def printTestResults():\n",
    "    # FILL THIS IN\n",
    "    # Hint: you need to iterate over the possible values of k: 1, 3 and 5. For each k, call getErrorPercentagek\n",
    "\n",
    "printTestResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3N5GwrmeJmq"
   },
   "source": [
    "**Note:** In a realistic situation we will not first try which value of *k* leads to the best results on the test data, but we will have to choose the value of *k* (or let the computer choose) **before** we see the test data. Usually we will do this on a separate dataset called the *development* dataset. This is an example of a general problem which we will encounter in all kinds of Machine Learning methods and on which we will pay a lot of attention in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHA5TFcHeJmq"
   },
   "source": [
    "# Programming practices\n",
    "\n",
    "## Copy-pasted code\n",
    "\n",
    "In this lab we have followed a very bad programming practice: copying and pasting code. For example, we copied computeDistance to then write computeDistance2, and then we copied computeDistance2 to write computeDistance3. In general, best practice is to avoid redundant copying and pasting, but instead to do one of the following:\n",
    "\n",
    "* if you want to replace the old functionality with the new one, simply edit the original function to have the new functionality\n",
    "\n",
    "* if you want to keep the old functionality along with the new one, edit the original function to be able to run in both modes\n",
    "\n",
    "When grading this lab, we will consider avoiding copy-pasting as a *bonus* 0.5 points (on the whole lab). The maximum grade will be capped at 8 points (you cannot score more than 8 points on the entire lab).\n",
    "\n",
    "## Explicitly stating the parameter types and return types\n",
    "\n",
    "Python allows you to explicitly state the parameter types and the return types, i.e., you can write method signatures as:\n",
    "\n",
    "`def get_some_boolean(param1):`\n",
    "\n",
    "but you can also write it as:\n",
    "\n",
    "`def get_some_boolean(param1: float) -> bool:`\n",
    "\n",
    "Both of these are correct, and we will not base our grading on this. Whatever you prefer is fine. We just want you to be aware of both possibilities, to avoid confusion on your end when reading our code.\n",
    "\n",
    "## Unit testing\n",
    "\n",
    "A good practice when writing code is to write unit tests. These allow you to test the functionality of your code in very controlled scenarios. You can use the unit tests provided above. If one of these fails, it probably means there is a bug in your code. However, we also note that you might have used slightly different function signatures, which might mean that our unit tests are not precisely tailored to your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uac584CWeJmq"
   },
   "source": [
    "## Congratulations! You have finished the required portion of the assignment.\n",
    "### If you have finished and want to challenge yourself a little further, you can attempt the following 2 extra questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1iurYR8eJmq"
   },
   "source": [
    "**12. Try what happens for higher values of $k$. Discuss your results in a short paragraph** (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pedygp-neJmq"
   },
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "# Hint: most of the work is done by just running getErrorPercentagek with other values for k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngqJXoBreJmr"
   },
   "source": [
    "Can you think of alternate distance metrics? One possible metric is *Manhattan distance*, also called *city block* distance, and related to *lasso*, a powerful method for improving the reliability of linear models.\n",
    "\n",
    "$dist_{MH} = \\sum_{i=1}^{d} \\lvert A_i - B_i \\rvert$\n",
    "\n",
    "https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "\n",
    "**13. Implement the manhattan distance metric. Is this a good metric for this problem? Discuss your results**  (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh3YIPxfeJmr"
   },
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "\"\"\"\n",
    "Hint: most of the work is done by changing the computeDistance3 function.\n",
    "However, you will also need to change the giveCredit function and the getErrorPercentage function\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
